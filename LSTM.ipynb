{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTMfghnhhIIf","executionInfo":{"status":"ok","timestamp":1620400749945,"user_tz":240,"elapsed":2698,"user":{"displayName":"Arjun Somayazulu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifkxdcjl-cADj37F9o8tUFVtpk_13z7RvCPwU20TU=s64","userId":"14375463672278382485"}},"outputId":"4cdad60a-b9c8-48da-9673-930380e8496b"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oR1Ks7SRhQHq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620400749947,"user_tz":240,"elapsed":2690,"user":{"displayName":"Arjun Somayazulu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifkxdcjl-cADj37F9o8tUFVtpk_13z7RvCPwU20TU=s64","userId":"14375463672278382485"}},"outputId":"440d5bfc-b29f-4d7a-eb54-36963dfee3fe"},"source":["## Mount Google Drive Data (If using Google Colaboratory)\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","except:\n","    print(\"Mounting Failed.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1CzoFW03hTzT"},"source":["from transformers import BertTokenizer\n","import pandas as pd\n","import numpy as np # linear algebra\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from nltk.corpus import stopwords \n","from collections import Counter\n","import string\n","import re\n","import seaborn as sns\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","import time\n","#df = pd.read_csv('drive/My Drive/DL-Final-Project/Dataset/Subset2_Preprocessed_NoHashtag.csv',  lineterminator='\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWO1lX2wifOY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620400751235,"user_tz":240,"elapsed":3965,"user":{"displayName":"Arjun Somayazulu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifkxdcjl-cADj37F9o8tUFVtpk_13z7RvCPwU20TU=s64","userId":"14375463672278382485"}},"outputId":"960e3145-f568-4318-e2ca-0e669b3d3479"},"source":["##tokenizer\n","\n","#training_data_file = '/content/gdrive/My Drive/Dataset/FINAL_DATASET_NOSTOPWORDS_2.csv'\n","training_data_file = 'drive/My Drive/DL-Final-Project/Dataset/FINAL_DATASET_NOHASHTAGS_2.csv'\n","#vocabulary = '/content/gdrive/My Drive/Dataset/bert-base-uncased-vocab.txt'  ##30522 tokens\n","vocabulary = 'drive/My Drive/DL-Final-Project/Dataset/bert-base-uncased-vocab.txt' \n","L = open(training_data_file,'r').readlines()\n","training_set = [{'sentence': L[i].split(',')[0], 'label': int((L[i].split(',')[1][:-1]).replace('-1','0'))} for i in range(1,len(L)) if len(L[i].split(',')) >= 2]\n","tokenizer = BertTokenizer(vocabulary)\n","\n","###example for LSTM\n","print(training_set[0])\n","print(tokenizer.encode(training_set[0]['sentence']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'sentence': 'rt lolpacorg why do we let the 1 control guns too please rt to show support for safe gun laws http t co qp', 'label': 1}\n","[101, 19387, 8840, 14277, 22684, 10623, 2339, 2079, 2057, 2292, 1996, 1015, 2491, 4409, 2205, 3531, 19387, 2000, 2265, 2490, 2005, 3647, 3282, 4277, 8299, 1056, 2522, 1053, 2361, 102]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-IjoY5aAkfre","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620400751236,"user_tz":240,"elapsed":3958,"user":{"displayName":"Arjun Somayazulu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifkxdcjl-cADj37F9o8tUFVtpk_13z7RvCPwU20TU=s64","userId":"14375463672278382485"}},"outputId":"7412676f-3ac6-4711-e599-73bedfa709b9"},"source":["is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, CPU used\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GPU is available\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ntp8Ztk6YhdE","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1620400751238,"user_tz":240,"elapsed":3950,"user":{"displayName":"Arjun Somayazulu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifkxdcjl-cADj37F9o8tUFVtpk_13z7RvCPwU20TU=s64","userId":"14375463672278382485"}},"outputId":"173cc9ef-b2d2-4041-adda-d7c1e8af4855"},"source":["df = pd.DataFrame(training_set)\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>rt lolpacorg why do we let the 1 control guns ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>leeterryne fact background checks already stop...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>rt jayandsteve hey a question nra are these pe...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>franklautenberg guns kill 8 children daily i d...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>nra wants 2 keep their guns 2 protect themselv...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  label\n","0  rt lolpacorg why do we let the 1 control guns ...      1\n","1  leeterryne fact background checks already stop...      1\n","2  rt jayandsteve hey a question nra are these pe...      1\n","3  franklautenberg guns kill 8 children daily i d...      1\n","4  nra wants 2 keep their guns 2 protect themselv...      1"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"QfdgDFkyZGaI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620400751239,"user_tz":240,"elapsed":3940,"user":{"displayName":"Arjun Somayazulu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifkxdcjl-cADj37F9o8tUFVtpk_13z7RvCPwU20TU=s64","userId":"14375463672278382485"}},"outputId":"fe3577ac-2d5b-4e5f-9ac0-749cc7da7785"},"source":["X,y = df['sentence'].values,df['label'].values\n","x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\n","\n","print(f'shape of train data is {x_train.shape}')\n","print(f'shape of test data is {x_test.shape}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["shape of train data is (12705,)\n","shape of test data is (4236,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"irdHxmMna1KI"},"source":["for i in range(len(x_train)):\n","    x_train[i] = tokenizer.encode(x_train[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i9xRHDwgc5gF"},"source":["for i in range(len(x_test)):\n","    x_test[i] = tokenizer.encode(x_test[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xbp9Ztm2ZjJ8","colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"status":"ok","timestamp":1620400760120,"user_tz":240,"elapsed":12802,"user":{"displayName":"Arjun Somayazulu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifkxdcjl-cADj37F9o8tUFVtpk_13z7RvCPwU20TU=s64","userId":"14375463672278382485"}},"outputId":"4e75b3eb-609d-4b2e-dd24-545e13a19a9a"},"source":["rev_len = [len(i) for i in x_train]\n","pd.Series(rev_len).hist()\n","plt.show()\n","pd.Series(rev_len).describe()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"execute_result","data":{"text/plain":["count    12705.000000\n","mean        26.460291\n","std          5.592705\n","min          5.000000\n","25%         23.000000\n","50%         26.000000\n","75%         30.000000\n","max         47.000000\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"6GV5tkGVaPpF"},"source":["def padding_(sentences, seq_len):\n","    features = np.zeros((len(sentences), seq_len),dtype=int)\n","    for ii, review in enumerate(sentences):\n","        if len(review) != 0:\n","            features[ii, -len(review):] = np.array(review)[:seq_len]\n","    return features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J60wlGFuZRx8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620400768787,"user_tz":240,"elapsed":21450,"user":{"displayName":"Arjun Somayazulu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifkxdcjl-cADj37F9o8tUFVtpk_13z7RvCPwU20TU=s64","userId":"14375463672278382485"}},"outputId":"be4594ba-d97f-46c1-8505-9300ef84d086"},"source":["X,y = df['sentence'].values,df['label'].values\n","for i in range(len(X)):\n","    X[i] = tokenizer.encode(X[i])\n","X = torch.from_numpy(padding_(X,40))\n","y = torch.from_numpy(y)\n","print(X.shape)\n","print(y.shape)\n","print(y)\n","print(sum(y))\n","print(len(y)-sum(y))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([16941, 40])\n","torch.Size([16941])\n","tensor([1, 1, 1,  ..., 1, 1, 1])\n","tensor(13352)\n","tensor(3589)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ypiuvBN-P-M8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620400768788,"user_tz":240,"elapsed":21445,"user":{"displayName":"Arjun Somayazulu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifkxdcjl-cADj37F9o8tUFVtpk_13z7RvCPwU20TU=s64","userId":"14375463672278382485"}},"outputId":"f9e46092-016e-48e6-a04f-58b9de02a9e8"},"source":["from torch.utils.data import TensorDataset, random_split, RandomSampler, SequentialSampler\n","\n","dataset = TensorDataset(X,y)\n","train_size = int(0.7 * len(dataset) )\n","val_size = int(0.15 * len(dataset))\n","test_size = len(dataset) - train_size - val_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))\n","print('{:>5,} test samples'.format(test_size))\n","\n","\n","\n","batch_size = 8\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size, # Trains with this batch size.\n","            drop_last=True\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size, # Evaluate with this batch size.\n","            drop_last=True\n","        )\n","\n","test_dataloader = DataLoader(\n","            test_dataset, # The validation samples.\n","            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size, # Evaluate with this batch size.\n","            drop_last=True\n","        )\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["11,858 training samples\n","2,541 validation samples\n","2,542 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FJacfeuYdRXG"},"source":["class LSTMModel(nn.Module):\n","    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n","        super(LSTMModel,self).__init__()\n"," \n","        self.output_dim = output_dim\n","        self.hidden_dim = hidden_dim\n"," \n","        self.no_layers = no_layers\n","        self.vocab_size = vocab_size\n","    \n","        # embedding and LSTM layers\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        #lstm\n","        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n","                           num_layers=no_layers,batch_first=True)\n","        \n","        \n","        # dropout layer\n","        self.dropout = nn.Dropout(0.6)\n","    \n","        # linear and sigmoid layer\n","        self.fc = nn.Linear(self.hidden_dim*40, output_dim)\n","        self.sig = nn.Sigmoid()\n","        \n","    def forward(self,x,hidden):\n","        batch_size = x.size(0)\n","        # embeddings and lstm_out\n","        \n","\n","        embeds = self.embedding(x)   # shape: B x S x Feature   since batch = True\n","        \n","        lstm_out, hidden = self.lstm(embeds, hidden)\n","        out = lstm_out.contiguous().view(batch_size,-1) ##use all lstm outputs\n","\n","        \n","        # dropout and fully connected layer\n","        out = self.dropout(out)\n","        out = self.fc(out)\n","        \n","        # sigmoid function\n","        sig_out = self.sig(out)\n","       \n","\n","        sig_out = sig_out[:, -1] # get last batch of labels\n","        \n","        # return last sigmoid output and hidden state\n","        return sig_out, hidden\n","        \n","        \n","        \n","    def init_hidden(self, batch_size):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n","        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n","        hidden = (h0,c0)\n","        return hidden\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AhU0qjzid2DC"},"source":["no_layers = 2\n","vocab_size = 30522 + 1 #extra 1 for padding\n","embedding_dim = 64\n","output_dim = 1\n","hidden_dim = 256\n","\n","model = LSTMModel(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSBbvRK6eOp2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620400779374,"user_tz":240,"elapsed":32011,"user":{"displayName":"Arjun Somayazulu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifkxdcjl-cADj37F9o8tUFVtpk_13z7RvCPwU20TU=s64","userId":"14375463672278382485"}},"outputId":"88b7ab68-2aec-48cf-e246-408def6aa2c9"},"source":["model.to(device)\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LSTMModel(\n","  (embedding): Embedding(30523, 64)\n","  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n","  (dropout): Dropout(p=0.6, inplace=False)\n","  (fc): Linear(in_features=10240, out_features=1, bias=True)\n","  (sig): Sigmoid()\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yqEPU5jteX1h"},"source":["# loss and optimization functions\n","lr=0.001\n","\n","# weights = torch.tensor([3589, 13352])\n","# weights = 1/ weights\n","# weights  = weights/torch.sum(weights)\n","# criterion = nn.BCELoss(weights)\n","criterion = nn.BCELoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","# function to predict accuracy\n","def acc(pred,label):\n","    pred = torch.round(pred.squeeze())\n","    return torch.sum(pred == label.squeeze()).item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lAYoyO6JeaTo","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"error","timestamp":1620401094502,"user_tz":240,"elapsed":288,"user":{"displayName":"Arjun Somayazulu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifkxdcjl-cADj37F9o8tUFVtpk_13z7RvCPwU20TU=s64","userId":"14375463672278382485"}},"outputId":"b2c86e36-8516-4702-eddf-571259a0191b"},"source":["clip = 5\n","epochs = 25\n","valid_loss_min = np.Inf\n","# train for some number of epochs\n","epoch_tr_loss,epoch_vl_loss = [],[]\n","epoch_tr_acc,epoch_vl_acc = [],[]\n","\n","for epoch in range(epochs):\n","    st = time.time()\n","    train_losses = []\n","    train_acc = 0.0\n","    model.train()\n","    # initialize hidden state \n","    h = model.init_hidden(batch_size)\n","    for inputs, labels in train_dataloader:\n","        inputs, labels = inputs.to(device), labels.to(device)   \n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","        h = tuple([each.data for each in h])\n","\n","        model.zero_grad()\n","        output,h = model(inputs,h)\n","        \n","        # calculate the loss and perform backprop\n","        \n","        loss = criterion(output.squeeze(), labels.float())\n","        loss.backward()\n","        train_losses.append(loss.item())\n","        # calculating accuracy\n","        accuracy = acc(output,labels)\n","        train_acc += accuracy\n","        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n"," \n","    \n","        \n","    val_h = model.init_hidden(batch_size)\n","    val_losses = []\n","    val_acc = 0.0\n","    model.eval()\n","    for inputs, labels in validation_dataloader:\n","            val_h = tuple([each.data for each in val_h])\n","\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            output, val_h = model(inputs, val_h)\n","            val_loss = criterion(output.squeeze(), labels.float())\n","\n","            val_losses.append(val_loss.item())\n","            \n","            accuracy = acc(output,labels)\n","            val_acc += accuracy\n","            \n","    epoch_train_loss = np.mean(train_losses)\n","    epoch_val_loss = np.mean(val_losses)\n","    epoch_train_acc = train_acc/len(train_dataloader.dataset)\n","    epoch_val_acc = val_acc/len(validation_dataloader.dataset)\n","    epoch_tr_loss.append(epoch_train_loss)\n","    epoch_vl_loss.append(epoch_val_loss)\n","    epoch_tr_acc.append(epoch_train_acc)\n","    epoch_vl_acc.append(epoch_val_acc)\n","    print(f'Epoch {epoch+1}') \n","    print('lapse:',time.time()-st)\n","    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n","    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n","    if epoch_val_loss <= valid_loss_min:\n","        #torch.save(model.state_dict(), '/content/gdrive/My Drive/Dataset/state_dict.pt')\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n","        valid_loss_min = epoch_val_loss\n","    print(25*'==')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([8])\n","torch.Size([8])\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-ce3e1d27f3ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2759\u001b[0;31m         \u001b[0mnew_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2760\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (2) at non-singleton dimension 0"]}]},{"cell_type":"code","metadata":{"id":"vkMxRyyam69_"},"source":["fig = plt.figure(figsize = (20, 6))\n","plt.subplot(1, 2, 1)\n","plt.plot(epoch_tr_acc, label='Train Acc')\n","plt.plot(epoch_vl_acc, label='Validation Acc')\n","plt.title(\"Accuracy\")\n","plt.legend()\n","plt.grid()\n","    \n","plt.subplot(1, 2, 2)\n","plt.plot(epoch_tr_loss, label='Train loss')\n","plt.plot(epoch_vl_loss, label='Validation loss')\n","plt.title(\"Loss\")\n","plt.legend()\n","plt.grid()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tQ25lcnKeDV2"},"source":["Record:\n"]},{"cell_type":"code","metadata":{"id":"8d5CQXX7eM_S"},"source":["from sklearn.metrics import classification_report\n","\n","test_h = model.init_hidden(batch_size)\n","test_acc = 0.0\n","true_label = torch.tensor([])\n","pred_label = torch.tensor([])\n","model.eval()\n","with torch.no_grad():\n","  for steps, (inputs, labels) in enumerate(test_dataloader):\n","    test_h = tuple([each.data for each in test_h])\n","\n","    inputs, labels = inputs.to(device), labels.to(device)\n","\n","    output, test_h = model(inputs, test_h)\n","    \n","    accuracy = acc(output,labels)\n","    test_acc += accuracy\n","    true_label = torch.cat((true_label,labels.cpu()),0)\n","    pred_label = torch.cat((pred_label,(output.cpu()).long()),0)\n","\n","print(classification_report(true_label.numpy(),pred_label.numpy()))"],"execution_count":null,"outputs":[]}]}